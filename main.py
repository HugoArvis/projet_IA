import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import warnings

warnings.filterwarnings('ignore')

# Imports des mod√®les optimis√©s
from optimized_models import (
    logistic_regression_optimized,
    svm_optimized,
    random_forest_optimized,
    xgboost_optimized,
    compare_models,
    plot_feature_importance
)

# Import de la validation crois√©e et du fine-tuning
from cross_validation import (
    cross_validate_all_models,
    create_comparison_table,
    plot_cv_results
)

from hyperparameter_tuning import (
    run_full_tuning,
    evaluate_tuned_models
)


def load_and_prepare_data(filepath='data/prepared_data.csv'):
    """
    Charge et pr√©pare les donn√©es avec normalisation
    """
    print("=" * 70)
    print("CHARGEMENT ET PR√âPARATION DES DONN√âES")
    print("=" * 70)

    # Charger les donn√©es
    data = pd.read_csv(filepath)
    print(f"‚úì Donn√©es charg√©es: {data.shape[0]} lignes, {data.shape[1]} colonnes")

    # S√©parer features et target
    X = data.drop('Attrition', axis=1)
    y = data['Attrition']

    # Afficher la distribution des classes
    print(f"\nDistribution des classes:")
    print(f"  - Classe 0 (Pas d'attrition): {sum(y == 0)} ({sum(y == 0) / len(y) * 100:.1f}%)")
    print(f"  - Classe 1 (Attrition): {sum(y == 1)} ({sum(y == 1) / len(y) * 100:.1f}%)")

    # Split des donn√©es
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"\n‚úì Train set: {len(X_train)} exemples")
    print(f"‚úì Test set: {len(X_test)} exemples")

    # CRUCIAL: Normaliser les donn√©es pour SVM
    print("\n‚úì Normalisation des donn√©es (StandardScaler)...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Convertir en DataFrame pour garder les noms de colonnes
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)

    return X_train_scaled, X_test_scaled, y_train, y_test, X.columns, scaler, X, y


def main(use_cv=True, use_tuning=True):
    """
    Fonction principale pour ex√©cuter tous les mod√®les

    Param√®tres:
    - use_cv: Si True, effectue d'abord une validation crois√©e avant le train/test final
    """
    # Charger et pr√©parer les donn√©es
    X_train, X_test, y_train, y_test, feature_names, scaler, X_full, y_full = load_and_prepare_data()

    # ========================================================================
    # √âTAPE 1: VALIDATION CROIS√âE (RECOMMAND√â)
    # ========================================================================

    if use_cv:
        print("\n" + "=" * 70)
        print("√âTAPE 1: VALIDATION CROIS√âE SUR L'ENSEMBLE D'ENTRA√éNEMENT")
        print("=" * 70)
        print("\nüí° La validation crois√©e permet de:")
        print("   - D√©tecter le sur-apprentissage")
        print("   - Obtenir une estimation plus robuste des performances")
        print("   - Utiliser efficacement toutes les donn√©es d'entra√Ænement")

        # Normaliser toutes les donn√©es pour la CV
        X_train_full_scaled = scaler.fit_transform(X_train)
        X_train_full_scaled = pd.DataFrame(X_train_full_scaled, columns=feature_names)

        # Ex√©cuter la validation crois√©e sur l'ensemble d'entra√Ænement
        all_results, all_cv_results = cross_validate_all_models(
            X_train_full_scaled, y_train,
            use_smote=True,
            n_splits=5
        )

        # Cr√©er le tableau comparatif
        cv_comparison = create_comparison_table(all_results)

        # Visualiser les r√©sultats
        plot_cv_results(all_results, all_cv_results)

        print("\n" + "=" * 70)
        print("‚úÖ VALIDATION CROIS√âE TERMIN√âE")
        print("=" * 70)
        print("\nüí° Passons maintenant √† l'√©valuation finale sur le test set...")

        if not use_tuning:
            input("\nAppuyez sur Entr√©e pour continuer...")

    # ========================================================================
    # √âTAPE 1.5: FINE-TUNING DES HYPERPARAM√àTRES (OPTIONNEL)
    # ========================================================================

    if use_tuning:
        print("\n" + "=" * 70)
        print("√âTAPE 1.5: FINE-TUNING DES HYPERPARAM√àTRES")
        print("=" * 70)
        print("\nüí° Le fine-tuning permet de:")
        print("   - Trouver les meilleurs hyperparam√®tres pour chaque mod√®le")
        print("   - Maximiser les performances (F1-Score, ROC-AUC)")
        print("   - √âviter le sur-apprentissage avec une validation crois√©e")
        print("\n‚ö†Ô∏è  Attention: Le fine-tuning peut prendre 10-30 minutes selon votre machine")

        response = input("\nVoulez-vous continuer avec le fine-tuning? (o/n): ")

        if response.lower() == 'o':
            # Lancer le fine-tuning complet
            tuned_models, best_params, tuning_results = run_full_tuning(
                X_train, X_test, y_train, y_test,
                use_smote=True,
                search_type='grid',  # 'grid' pour exhaustif, 'random' pour plus rapide
                small_grid=True  # True pour tests rapides, False pour recherche compl√®te
            )

            print("\n" + "=" * 70)
            print("‚úÖ FINE-TUNING TERMIN√â")
            print("=" * 70)
            print("\nüí° Les mod√®les optimis√©s sont maintenant disponibles dans tuned_models/")
            print("üí° Vous pouvez les charger avec joblib.load() pour vos pr√©dictions")

            # Terminer ici si fine-tuning activ√©
            print("\n" + "=" * 70)
            print("ANALYSE TERMIN√âE AVEC FINE-TUNING")
            print("=" * 70)
            return
        else:
            print("\n‚è≠Ô∏è  Fine-tuning ignor√©, passage √† l'entra√Ænement standard...")

        input("\nAppuyez sur Entr√©e pour continuer...")

    # ========================================================================
    # √âTAPE 2: ENTRA√éNEMENT ET √âVALUATION FINALE SUR TEST SET
    # ========================================================================

    print("\n" + "=" * 70)
    print("√âTAPE 2: ENTRA√éNEMENT FINAL ET √âVALUATION SUR TEST SET")
    print("=" * 70)

    # ========================================================================
    # MOD√àLE 1: R√âGRESSION LOGISTIQUE
    # ========================================================================
    print("\n" + "-" * 70)
    print("1. R√âGRESSION LOGISTIQUE")
    print("-" * 70)

    lr_model, lr_report, lr_cm, lr_proba = logistic_regression_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # MOD√àLE 2: SVM (VERSION RAPIDE)
    # ========================================================================
    print("\n" + "-" * 70)
    print("2. SVM (OPTIMIS√â POUR LA VITESSE)")
    print("-" * 70)

    svm_model, svm_report, svm_cm, svm_proba = svm_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # MOD√àLE 3: RANDOM FOREST
    # ========================================================================
    print("\n" + "-" * 70)
    print("3. RANDOM FOREST")
    print("-" * 70)

    rf_model, rf_report, rf_cm, rf_proba = random_forest_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # MOD√àLE 4: XGBOOST
    # ========================================================================
    print("\n" + "-" * 70)
    print("4. XGBOOST")
    print("-" * 70)

    xgb_model, xgb_report, xgb_cm, xgb_proba = xgboost_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # COMPARAISON DES MOD√àLES SUR TEST SET
    # ========================================================================
    print("\n" + "=" * 70)
    print("COMPARAISON DES MOD√àLES (TEST SET)")
    print("=" * 70)

    models_dict = {
        'Logistic Regression': (lr_model, lr_proba),
        'SVM': (svm_model, svm_proba),
        'Random Forest': (rf_model, rf_proba),
        'XGBoost': (xgb_model, xgb_proba)
    }

    compare_models(models_dict, X_test, y_test)

    # ========================================================================
    # ANALYSE DES FEATURES IMPORTANTES
    # ========================================================================
    print("\n" + "=" * 70)
    print("IMPORTANCE DES CARACT√âRISTIQUES")
    print("=" * 70)

    # Pour la r√©gression logistique
    plot_feature_importance(lr_model, feature_names, model_type='logistic', top_n=15)

    # Afficher les top features
    importance = lr_model.coef_[0]
    feature_importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Coefficient': importance,
        'Abs_Coefficient': np.abs(importance)
    }).sort_values('Abs_Coefficient', ascending=False)

    print("\nTop 10 features les plus importantes (R√©gression Logistique):")
    print(feature_importance_df.head(10)[['Feature', 'Coefficient']])

    # ========================================================================
    # R√âSUM√â FINAL
    # ========================================================================
    print("\n" + "=" * 70)
    print("R√âSUM√â FINAL")
    print("=" * 70)

    if use_cv:
        print("\n‚úÖ VALIDATION CROIS√âE:")
        print("   - D√©tection du sur-apprentissage: OK")
        print("   - Estimation robuste des performances: OK")
        print("   - R√©sultats sauvegard√©s dans: cv_results/")

    print("\n‚úÖ √âVALUATION FINALE (TEST SET):")
    print("   - Tous les mod√®les entra√Æn√©s et √©valu√©s")
    print("   - Comparaison des performances effectu√©e")
    print("   - Features importantes identifi√©es")

    print("\n" + "=" * 70)
    print("ANALYSE TERMIN√âE")
    print("=" * 70)
    print("\nüí° RECOMMANDATIONS:")
    print("  ‚úì Les mod√®les sont optimis√©s et √©quilibr√©s avec SMOTE")
    print("  ‚úì La validation crois√©e a permis de d√©tecter le sur-apprentissage")
    print("  ‚úì Le SVM est rapide gr√¢ce √† kernel='linear' et normalisation")
    print("  ‚úì Les features importantes sont correctement identifi√©es")
    print("\nüìä PROCHAINES √âTAPES:")
    print("  1. Optimiser les hyperparam√®tres avec GridSearchCV")
    print("  2. Tester des techniques d'ensemble (stacking, voting)")
    print("  3. Analyser les erreurs de classification en d√©tail")
    print("  4. Ajuster le seuil de d√©cision selon les besoins m√©tier")


if __name__ == "__main__":
    # Option 1: Analyse compl√®te avec validation crois√©e ET fine-tuning (MEILLEUR MAIS LENT)
    # main(use_cv=True, use_tuning=True)

    # Option 2: Validation crois√©e seulement (RECOMMAND√â)
    main(use_cv=True, use_tuning=False)

    # Option 3: Sans validation crois√©e ni tuning (RAPIDE mais moins robuste)
    # main(use_cv=False, use_tuning=False)