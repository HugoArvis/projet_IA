import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import warnings

warnings.filterwarnings('ignore')

# Imports des modÃ¨les optimisÃ©s
from optimized_models import (
    logistic_regression_optimized,
    svm_optimized,
    random_forest_optimized,
    xgboost_optimized,
    compare_models,
    plot_feature_importance
)

# Import de la validation croisÃ©e
from cross_validation import (
    cross_validate_all_models,
    create_comparison_table,
    plot_cv_results
)


def load_and_prepare_data(filepath='data/prepared_data.csv'):
    """
    Charge et prÃ©pare les donnÃ©es avec normalisation
    """
    print("=" * 70)
    print("CHARGEMENT ET PRÃ‰PARATION DES DONNÃ‰ES")
    print("=" * 70)

    # Charger les donnÃ©es
    data = pd.read_csv(filepath)
    print(f"âœ“ DonnÃ©es chargÃ©es: {data.shape[0]} lignes, {data.shape[1]} colonnes")

    # SÃ©parer features et target
    X = data.drop('Attrition', axis=1)
    y = data['Attrition']

    # Afficher la distribution des classes
    print(f"\nDistribution des classes:")
    print(f"  - Classe 0 (Pas d'attrition): {sum(y == 0)} ({sum(y == 0) / len(y) * 100:.1f}%)")
    print(f"  - Classe 1 (Attrition): {sum(y == 1)} ({sum(y == 1) / len(y) * 100:.1f}%)")

    # Split des donnÃ©es
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"\nâœ“ Train set: {len(X_train)} exemples")
    print(f"âœ“ Test set: {len(X_test)} exemples")

    # CRUCIAL: Normaliser les donnÃ©es pour SVM
    print("\nâœ“ Normalisation des donnÃ©es (StandardScaler)...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Convertir en DataFrame pour garder les noms de colonnes
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)

    #sauvegarder le  scaler pour une utilisation future
    import joblib
    import os
    os.makedirs('trained_models', exist_ok=True)
    joblib.dump(scaler, 'trained_models/scaler.pkl')
    print("[SAVE] Scaler sauvegarde: trained_models/scaler.pkl")

    return X_train_scaled, X_test_scaled, y_train, y_test, X.columns, scaler, X, y


def main(use_cv=True):
    """
    Fonction principale pour exÃ©cuter tous les modÃ¨les

    ParamÃ¨tres:
    - use_cv: Si True, effectue d'abord une validation croisÃ©e avant le train/test final
    """
    # Charger et prÃ©parer les donnÃ©es
    X_train, X_test, y_train, y_test, feature_names, scaler, X_full, y_full = load_and_prepare_data()

    # ========================================================================
    # Ã‰TAPE 1: VALIDATION CROISÃ‰E (RECOMMANDÃ‰)
    # ========================================================================

    if use_cv:
        print("\n" + "=" * 70)
        print("Ã‰TAPE 1: VALIDATION CROISÃ‰E SUR L'ENSEMBLE D'ENTRAÃŽNEMENT")
        print("=" * 70)
        print("\nðŸ’¡ La validation croisÃ©e permet de:")
        print("   - DÃ©tecter le sur-apprentissage")
        print("   - Obtenir une estimation plus robuste des performances")
        print("   - Utiliser efficacement toutes les donnÃ©es d'entraÃ®nement")

        # Normaliser toutes les donnÃ©es pour la CV
        X_train_full_scaled = scaler.fit_transform(X_train)
        X_train_full_scaled = pd.DataFrame(X_train_full_scaled, columns=feature_names)

        # ExÃ©cuter la validation croisÃ©e sur l'ensemble d'entraÃ®nement
        all_results, all_cv_results = cross_validate_all_models(
            X_train_full_scaled, y_train,
            use_smote=True,
            n_splits=5
        )

        # CrÃ©er le tableau comparatif
        cv_comparison = create_comparison_table(all_results)

        # Visualiser les rÃ©sultats
        plot_cv_results(all_results, all_cv_results)

        print("\n" + "=" * 70)
        print("âœ… VALIDATION CROISÃ‰E TERMINÃ‰E")
        print("=" * 70)
        print("\nðŸ’¡ Passons maintenant Ã  l'Ã©valuation finale sur le test set...")
        input("\nAppuyez sur EntrÃ©e pour continuer...")

    # ========================================================================
    # Ã‰TAPE 2: ENTRAÃŽNEMENT ET Ã‰VALUATION FINALE SUR TEST SET
    # ========================================================================

    print("\n" + "=" * 70)
    print("Ã‰TAPE 2: ENTRAÃŽNEMENT FINAL ET Ã‰VALUATION SUR TEST SET")
    print("=" * 70)

    # ========================================================================
    # MODÃˆLE 1: RÃ‰GRESSION LOGISTIQUE
    # ========================================================================
    print("\n" + "-" * 70)
    print("1. RÃ‰GRESSION LOGISTIQUE")
    print("-" * 70)

    lr_model, lr_report, lr_cm, lr_proba = logistic_regression_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # MODÃˆLE 2: SVM (VERSION RAPIDE)
    # ========================================================================
    print("\n" + "-" * 70)
    print("2. SVM (OPTIMISÃ‰ POUR LA VITESSE)")
    print("-" * 70)

    svm_model, svm_report, svm_cm, svm_proba = svm_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # MODÃˆLE 3: RANDOM FOREST
    # ========================================================================
    print("\n" + "-" * 70)
    print("3. RANDOM FOREST")
    print("-" * 70)

    rf_model, rf_report, rf_cm, rf_proba = random_forest_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # MODÃˆLE 4: XGBOOST
    # ========================================================================
    print("\n" + "-" * 70)
    print("4. XGBOOST")
    print("-" * 70)

    xgb_model, xgb_report, xgb_cm, xgb_proba = xgboost_optimized(
        X_train, X_test, y_train, y_test,
        use_smote=True,
        use_saved_model=False
    )

    # ========================================================================
    # COMPARAISON DES MODÃˆLES SUR TEST SET
    # ========================================================================
    print("\n" + "=" * 70)
    print("COMPARAISON DES MODÃˆLES (TEST SET)")
    print("=" * 70)

    models_dict = {
        'Logistic Regression': (lr_model, lr_proba),
        'SVM': (svm_model, svm_proba),
        'Random Forest': (rf_model, rf_proba),
        'XGBoost': (xgb_model, xgb_proba)
    }

    compare_models(models_dict, X_test, y_test)

    # ========================================================================
    # ANALYSE DES FEATURES IMPORTANTES
    # ========================================================================
    print("\n" + "=" * 70)
    print("IMPORTANCE DES CARACTÃ‰RISTIQUES")
    print("=" * 70)

    # Pour la rÃ©gression logistique
    plot_feature_importance(lr_model, feature_names, model_type='logistic', top_n=15)

    # Afficher les top features
    importance = lr_model.coef_[0]
    feature_importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Coefficient': importance,
        'Abs_Coefficient': np.abs(importance)
    }).sort_values('Abs_Coefficient', ascending=False)

    print("\nTop 10 features les plus importantes (RÃ©gression Logistique):")
    print(feature_importance_df.head(10)[['Feature', 'Coefficient']])

    # ========================================================================
    # RÃ‰SUMÃ‰ FINAL
    # ========================================================================
    print("\n" + "=" * 70)
    print("RÃ‰SUMÃ‰ FINAL")
    print("=" * 70)

    if use_cv:
        print("\nâœ… VALIDATION CROISÃ‰E:")
        print("   - DÃ©tection du sur-apprentissage: OK")
        print("   - Estimation robuste des performances: OK")
        print("   - RÃ©sultats sauvegardÃ©s dans: cv_results/")

    print("\nâœ… Ã‰VALUATION FINALE (TEST SET):")
    print("   - Tous les modÃ¨les entraÃ®nÃ©s et Ã©valuÃ©s")
    print("   - Comparaison des performances effectuÃ©e")
    print("   - Features importantes identifiÃ©es")

    print("\n" + "=" * 70)
    print("ANALYSE TERMINÃ‰E")
    print("=" * 70)
    print("\nðŸ’¡ RECOMMANDATIONS:")
    print("  âœ“ Les modÃ¨les sont optimisÃ©s et Ã©quilibrÃ©s avec SMOTE")
    print("  âœ“ La validation croisÃ©e a permis de dÃ©tecter le sur-apprentissage")
    print("  âœ“ Le SVM est rapide grÃ¢ce Ã  kernel='linear' et normalisation")
    print("  âœ“ Les features importantes sont correctement identifiÃ©es")
    print("\nðŸ“Š PROCHAINES Ã‰TAPES:")
    print("  1. Optimiser les hyperparamÃ¨tres avec GridSearchCV")
    print("  2. Tester des techniques d'ensemble (stacking, voting)")
    print("  3. Analyser les erreurs de classification en dÃ©tail")
    print("  4. Ajuster le seuil de dÃ©cision selon les besoins mÃ©tier")


if __name__ == "__main__":
    # Option 1: Avec validation croisÃ©e (RECOMMANDÃ‰)
    main(use_cv=True)

    # Option 2: Sans validation croisÃ©e (plus rapide)
    # main(use_cv=False)